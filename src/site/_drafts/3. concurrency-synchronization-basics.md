---
layout: post
title: "Concurrency: Synchronization and Deadlocks"
date: 2024-01-11 09:00:00 +0100
author: Tobias Ritzau
categories: wip post blog cs concurrency synchronization deadlock
---

> Intro and reference back to foundations

## Synchronizing Data Access

So what is left? These techniques mentioned above all avoids the data race and those will take you far, but you may still end up in situations where they are not enough. They are enough to handle data races, but you can end up with data races when multiple resources needs to be updated atomically. Other examples include needing to conditionally wake up other threads but that is a topic for another note.

Consider a bank transaction where funds are transfered from one account to another. You will need to remove funds from one account and add to another. This needs to be atomically otherwise someone may see a state where the total funds does not add up. In this case atomics are not sufficient, you could do the operation on a single thread using a queue, but you may also use a mutex. The Java Virtual Machine (JVM) is interesting in many ways, one being that all object instances has a mutex. The following Kotlin example will show you how a bank transfer can be implemted.

It is **very** important to note that **all** access to involved variables needs to be synchronized using the same mutex. That means that, for example, read access also needs to by synchronized to be thread safe.

```kotlin
class Bank(var accountA: Int, var accountB: Int) {
  private val lock = object {}

  fun transfer(amount: Int) = synchronized(lock) {
    accountA -= amount
    accountB += amount
  }

  fun totalFunds(): Int = synchronized(lock) {
    return accountA + accountB
  }
}
```

We mentioned above that using the atomic reference counted references in Rust, the data access is by default immutable. Using a mutex will allow us to mutate the data. The code is similar to before, but now we keep a `Mutex` in the Arc. To access the data within, we need to lock the mutex which ensures that there is no data race. Note that the lock is held during the lifetime of the returned reference.

```rust
let counter = Arc::new(Mutex::new(0));

let t = thread::spawn({
    let counter_alias = counter.clone();
    move || {
        let mut c = counter_alias.lock().unwrap();
        *c += 42;
    }
});

t.join().unwrap();
let result = counter.lock().unwrap();
println!("counter {} from the main thread!", result);
```

## Deadlocks

> When two trains approach each other at a crossing, both shall come to a full stop and neither shall start up again until the other has gone.

**Deadlocks**: These are more complex. When a deadlock occurs, the involved threads freeze. Consider the Dining Philosophers Problem: a group of philosophers sit around a table, with a chopstick between each of them. A philosopher needs two sticks to eat but can only pick one at a time. If every philosopher picks up one stick and waits for the other, none can eat, leading to a deadlock. In coding, deadlocks occur when multiple processes wait on each other to release resources, creating a standstill.

### What Can We Do About It?

So, you need the efficiency, how can you use concurrency safely? As Mr. Miyagi wisely advised in karate, “The best defense is no be there.” This philosophy is just as applicable in managing race conditions.

**Avoiding Race Conditions**: The ideal approach is to design your system to avoid race conditions altogether. This can be done in two ways: by ensuring data is accessed by only one thread (common in UI frameworks like iOS, Android, and web applications) or by avoiding shared data altogether. In environments like Rust and with Web Workers, race conditions are circumvented by either making each thread work with its own copy of the data, eliminating races, or by transferring data ownership between threads, thus avoiding concurrent access. Fixme: Add section in thread safe data structures.

**Synchronization When Avoidance Isn’t Possible**: If avoiding race conditions isn't feasible, then the next step is to synchronize access to shared resources. The key here is isolation – keep the synchronized code as simple, brief, and isolated as possible, ideally in a separate file. This makes it easier to understand and reduces the risk of errors.

**Mutexes for Synchronization**: One common tool for synchronization is the Mutex (or lock). A mutex ensures that only one owner (be it a thread or a process) can access a resource at any given time. However, be cautious with recursive mutexes, as they can lead to a thread deadlocking itself if not handled correctly.

**Scoped Mutexes**: Some systems provide scoped mutexes which automatically unlock at the end of a scope. This is helpful as it prevents forgetting to release the lock, but be aware, it doesn't eliminate the risk of deadlocks.

**Avoiding Deadlocks**: Deadlocks occur when a process holding a resource is waiting for another resource, which is also being held. To simplify, try to never hold a lock while attempting to acquire another. If you must hold multiple locks, lock them all at once. And most crucially, avoid holding a lock while calling external code, such as callbacks, as this significantly increases the risk of a deadlock.

## Key Takeaways

- **Leveraging Concurrency for Efficiency**: Concurrency is a powerful tool to enhance the performance of your code, particularly on modern multi-core processors, allowing for parallel task execution.
- **Essential for UI Responsiveness**: In applications like mobile apps, concurrency is vital to prevent blocking the UI thread, ensuring a smooth and responsive user interface.
- **Diverse Techniques for Implementation**: Implementing concurrency can be achieved through various methods, including threads, executors/queues, and coroutines, each suitable for different scenarios and needs.
- **Navigating Race Conditions**: One of the primary challenges in concurrent programming is avoiding race conditions. These occur when multiple threads access the same data simultaneously, with at least one modifying it, potentially leading to inconsistent results.
- **Strategies to Prevent Race Conditions**:
  - Ensure exclusive data access by a single thread.
  - Use thread-safe data structures and atomic operations.
  - Employ data copying or handover strategies for thread exclusivity.
  - Embrace immutability where feasible.
- **The Role of Synchronization**: When necessary, synchronization, primarily through mutexes, can manage data access across threads but must be used judiciously to balance performance.
- **Deadlock Prevention**: A critical aspect of using synchronization is avoiding deadlocks, which can be achieved by avoiding holding one mutex while waiting for another and being cautious with callback invocations within locked contexts.

These insights offer a comprehensive overview of concurrency, its benefits, challenges, and strategies for safe and efficient implementation. Equipped with this knowledge, you're prepared to tackle concurrency in your coding projects with confidence.

vs.

- Concurrency can be used to increase the efficiency of your code.
- Sometimes concurrency is required to avoid blocking the UI thread.
- There are several techniques to write concurrent code: threads,
  executors/queues, and coroutines.
- Race conditions may occur if multiple threads access the same data, and at least one is writing.
- A simple strategy to avoid race conditions is to ensure that these conditions
  are not met.
  - Only allow access from a single thread
  - Copy data to give each thread its own copy
  - Hand over data so that only one thread can access it at any given time
  - Use immutable data.
  - Use thread safe data structures (including atomics).
- Sometimes performance requires synchronization
- Mutexes can be used to synchronize data access
- Synchronization can cause deadlocks
- Deadlocks can be avoided if you never hold a Mutex while waiting for another.
- Most importantly, never invoke a callback with a locked mutex.

## Where to go from here?

As we've explored in "Concurrency 101," the efficient implementation of concurrency is crucial in modern software development, offering significant performance enhancements. However, it's equally important to be mindful of the pitfalls that come with it, namely race conditions and deadlocks. Here are the key takeaways:

- **Concurrency for Efficiency**: Just like multiple lanes on a freeway, concurrency allows your software to perform multiple operations in parallel, maximizing the use of modern multi-core processors.
- **Avoid Race Conditions**: The best strategy to handle race conditions is to avoid them altogether, either by limiting data access to a single thread or by ensuring no shared data is accessed concurrently.
- **Effective Synchronization**: When avoidance isn’t possible, careful synchronization is key. Isolate synchronized code, keep it simple, and use tools like mutexes wisely.
- **Beware of Deadlocks**: Always be cautious of deadlocks, especially when using locks. Avoid holding multiple locks if possible, and never hold a lock while calling external code.

As you begin to integrate these principles into your projects, you'll likely encounter more complex scenarios and challenges. In the next section, "Advanced Concurrency Concepts," we'll dive deeper into sophisticated synchronization mechanisms, explore language-specific features, and discuss how to navigate the intricacies of concurrent programming in more complex environments. Stay tuned as we unlock the next level of concurrency mastery!

## Terminology

- Concurrency
- Data race
- Race condtition
- Thread
